{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e80e23-7227-4e5f-83ba-bbfd4fd430ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab0af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aafd3450-fde7-44fe-aef7-e631df94bff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/users/w32zhong/anaconda/lg/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Re-)Loading modeling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/users/w32zhong/anaconda/lg/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modeling_llama import LlamaForCausalLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707ea855-07a2-4544-8edd-bfeea3d4d773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3237a68b73b4f7cbc46627b3e57c365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/users/w32zhong/anaconda/lg/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/mnt/users/w32zhong/anaconda/lg/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.nn.Linear.reset_parameters = lambda x: None\n",
    "model = LlamaForCausalLM.from_pretrained('NousResearch/Llama-2-13b-chat-hf', torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "277a49c1-0fd8-4a41-bf62-7acd877c44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda:0').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5dc125-c5d0-49ff-b929-d70a5cbca2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('NousResearch/Llama-2-13b-chat-hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9808aa5d-eaa9-4f26-b147-623bf279e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3620ee-5cb8-41d3-b183-aaeaad245163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/users/w32zhong/anaconda/lg/lib/python3.8/site-packages/datasets/load.py:1429: FutureWarning: The repository for xsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/xsum\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xsum = load_dataset('xsum').shuffle(4242)\n",
    "cnn = load_dataset('cnn_dailymail', '3.0.0').shuffle(4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1192abb-d217-4778-b7a9-17c00c4f8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    item = cnn['train'][i+100]\n",
    "    cnn_context = 'Article: ' + item['article'] + '\\nSummary: ' + item['highlights'].replace('\\n', '')\n",
    "    \n",
    "    item = cnn['train'][i]\n",
    "    prompt = cnn_context + '\\nArticle: ' + item['article'] + '\\nSummary:'\n",
    "    prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea3ed14c-e0a7-4c79-81bb-1e97e87e8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    item = xsum['train'][i+100]\n",
    "    xsum_context = 'Article: ' + item['document'] + '\\nSummary: ' + item['summary'].replace('\\n', '')\n",
    "    \n",
    "    item = xsum['train'][i]\n",
    "    prompt = xsum_context + '\\nArticle: ' + item['document'] + '\\nSummary:'\n",
    "    prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4df0eccd-4f1c-4043-8ed1-af4a2078e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from searching import LayerSkippingSearching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "671854ee-2992-46f1-a43f-477afcd76bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_searching = LayerSkippingSearching(model, tokenizer, prompts, evaluate_config={\"generate_fn\": \"essg\", \"max_new_tokens\": 32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53d16ef-1225-499d-b8fd-f5e67d2fc1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_searching.probe([8,10,15,18,20,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,], [])\n",
    "layer_searching.probe([3, 5, 6, 8, 10, 11, 14, 15, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37], [6, 9, 10, 11, 15, 24, 25, 27, 28, 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45336d0f-21a0-43d8-8c54-a4a819040b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    x0     |    x1     |    x10    |    x11    |    x12    |    x13    |    x14    |    x15    |    x16    |    x17    |    x18    |    x19    |    x2     |    x20    |    x21    |    x22    |    x23    |    x24    |    x25    |    x26    |    x27    |    x28    |    x29    |    x3     |    x30    |    x31    |    x32    |    x33    |    x34    |    x35    |    x36    |    x37    |    x38    |    x39    |    x4     |    x40    |    x41    |    x42    |    x43    |    x44    |    x45    |    x46    |    x47    |    x48    |    x49    |    x5     |    x50    |    x51    |    x52    |    x53    |    x54    |    x55    |    x56    |    x57    |    x58    |    x59    |    x6     |    x60    |    x61    |    x62    |    x63    |    x64    |    x65    |    x66    |    x67    |    x68    |    x69    |    x7     |    x70    |    x71    |    x72    |    x73    |    x74    |    x75    |    x76    |    x77    |    x78    |    x79    |    x8     |    x9     |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Log: 12.584338405263694 tokens/s Skipped attn: 19 Skipped mlp: 20\n",
      "Log: 14.925325874992163 tokens/s Skipped attn: 25 Skipped mlp: 10\n",
      "=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3,\n",
       "  5,\n",
       "  6,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  18,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37],\n",
       " [6, 9, 10, 11, 15, 24, 25, 27, 28, 35])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_searching.search(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32f50131-abea-4a35-b9a1-f13a83c73e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3,\n",
       "  5,\n",
       "  6,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  18,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37],\n",
       " [6, 9, 10, 11, 15, 24, 25, 27, 28, 35])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_searching.get_solution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('lg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b2b2094df3d20f295831499431d281eb5aad8ff21e32741728a6f192e048c21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
