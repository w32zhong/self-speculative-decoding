{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/users/w32zhong/anaconda/lg/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/mnt/users/w32zhong/anaconda/lg/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Re-)Loading modeling...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modeling_llama import LlamaForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from decoding import clip_input, infer_input_ids\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d851e7b12bc847e1a2f610823a9e8160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/users/w32zhong/anaconda/lg/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/mnt/users/w32zhong/anaconda/lg/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.nn.Linear.reset_parameters = lambda x: None\n",
    "model = LlamaForCausalLM.from_pretrained('NousResearch/Llama-2-13b-chat-hf', torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained('NousResearch/Llama-2-13b-chat-hf')\n",
    "device='cuda:2'\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "2.3.0.dev20231230+cu118\n",
      "4.33.1\n"
     ]
    }
   ],
   "source": [
    "# -*- encoding:utf-8 -*-\n",
    "import transformers\n",
    "print(torch.version.cuda)\n",
    "print(torch.__version__) \n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 6, 8, 10, 11, 14, 15, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37] [6, 9, 10, 11, 15, 24, 25, 27, 28, 35]\n"
     ]
    }
   ],
   "source": [
    "_attn_skip_layer_id_set, _mlp_skip_layer_id_set =model.get_skip_layers()\n",
    "print(_attn_skip_layer_id_set, _mlp_skip_layer_id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "n_shot = 1\n",
    "task_name = 'cnndm'\n",
    "prompt_shots = ''\n",
    "if task_name == 'xsum':\n",
    "    data = load_dataset('xsum', split='test').shuffle(seed=seed).select(range(1000))\n",
    "    shots = load_dataset('xsum',split='train').shuffle(seed=seed).select(range(n_shot))\n",
    "    prompt_keys=['document','summary']\n",
    "elif task_name == 'cnndm':\n",
    "    data = load_dataset('cnn_dailymail', name='3.0.0', split='test') .shuffle(seed=seed).select(range(1000))\n",
    "    shots = load_dataset('cnn_dailymail', name='3.0.0', split='train').shuffle(seed=seed).select(range(n_shot))\n",
    "    prompt_keys=['article','highlights']\n",
    "for i in range(n_shot):\n",
    "    prompt = 'Article: ' + shots[i][prompt_keys[0]] + '\\nSummary: ' + shots[i][prompt_keys[1]].replace('\\n', '') + '\\n'\n",
    "    prompt_shots += prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: By . Anthony Bond . PUBLISHED: . 07:03 EST, 2 March 2013 . | . UPDATED: . 08:07 EST, 2 March 2013 . Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide poisoning from a cooker. Tragic: The inquests have opened into the deaths of three members of the same family who were found in their static caravan last weekend. John and Audrey Cook are pictured . Awful: The family died following carbon monoxide poisoning at this caravan at the Tremarle Home Park in Camborne, Cornwall . It is also believed there was no working carbon monoxide detector in the static caravan. Cornwall Fire and Rescue Service said this would have resulted in the three being unconscious 'within minutes', . A spokesman for Cornwall coroner Dr Emma Carlyon confirmed the inquests were opened and adjourned yesterday afternoon. They will resume at a later date. Devon and Cornwall Police confirmed on Monday that carbon monoxide poisoning had been established as the cause of death. A police spokesman said the source of the poisoning was 'believed to be from incorrect operation of the gas cooker'. Poisoning: This woman left flowers outside the caravan following the deaths. It has emerged that the trio would have been unconscious 'within minutes' Touching: This tribute was left outside the caravan following news of the deaths . Early readings from experts at the site revealed a potentially lethal level of carbon monoxide present within the caravan at the time it was taken, shortly after the discovery of the bodies. Friends and neighbours have paid tribute to the trio. One . neighbour, Sonya Owen, 53, said: 'It's very distressing. I knew the . daughter, she was living her with her mum and dad. Everybody is really . upset.' Margaret Holmes, 65, who lived near the couple and their . daughter, said: 'They had lived here for around 40 years and they kept . themselves to themselves. 'I just can’t believe this has . happened, it is so sad and I am so shocked, I think we all are, you just . don’t expect this sort of thing to happen on your doorstep. 'Everyone will miss them, we used to chat a lot when we were both in the garden. 'I would just like to send my condolences to their family, I can’t imagine what they’re going through.' Nic Clark, 52, who was good friends with daughter Maureen, added: 'They were a lovely kind family, a great trio. 'Maureen . used to go out and walk her dog, a little Jack Russell, it is so sad . what has happened, I understand the dog went with them. 'They . will be sorely missed and I think everyone is just in shock at the . moment, I would like to send my condolences to the Cook family.'\n",
      "Summary: John and .Audrey Cook were discovered alongside their daughter, Maureen .They were found at Tremarle Home Park in Cornwall .Investigators say the three died of carbon monoxide .poisoning .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article': '(CNN) I see signs of a revolution everywhere. I see it in the op-ed pages of the newspapers, and on the state ballots in nearly half the country. I see it in politicians who once preferred to play it safe with this explosive issue but are now willing to stake their political futures on it. I see the revolution in the eyes of sterling scientists, previously reluctant to dip a toe into this heavily stigmatized world, who are diving in head first. I see it in the new surgeon general who cites data showing just how helpful it can be. I see a revolution in the attitudes of everyday Americans. For the first time a majority, 53%, favor its legalization, with 77% supporting it for medical purposes. Support for legalization has risen 11 points in the past few years alone. In 1969, the first time Pew asked the question about legalization, only 12% of the nation was in favor. I see a revolution that is burning white hot among young people, but also shows up among the parents and grandparents in my kids\\' school. A police officer I met in Michigan is part of the revolution, as are the editors of the medical journal, Neurosurgery. I see it in the faces of good parents, uprooting their lives to get medicine for their children -- and in the children themselves, such as Charlotte, who went from having 300 seizures a week to just one or two a month. We know it won\\'t consistently have such dramatic results (or any impact at all) in others, but what medicine does? I see this medical marijuana revolution in surprising places. Girl\\'s seizures spur medical marijuana legislation in Georgia . Among my colleagues, my patients and my friends. I have even seen the revolution in my own family. A few years ago, when I told my mother I was investigating the topic for a documentary, I was met with a long pause. \"Marijuana...?\" She whispered in a half questioning, half disapproving tone. She could barely even say the word and her response filled me with self-doubt. Even as a grown man, mom can still make my cheeks turn red and shatter my confidence with a single word. But just last week she suddenly stopped mid-conversation and said, \"I am proud of you on the whole marijuana thing.\" I waited for the other shoe to drop, but it didn\\'t. Instead, she added, \"You probably helped a lot of people who were suffering.\" I don\\'t think we had ever had a conversation like that one. At that moment, I saw a revolution that can bring you to tears. The word revolution, comes from the Latin revolutio, to \"turn around.\" I had my own turn around a couple of years ago, and at the time it was a lonely place to hold a supportive position on medical marijuana. Hardly any government officials would agree to sit down and be interviewed on the topic. Even patients I spoke to were reluctant to share their stories. It can be tricky, I learned, to be on the right side of science but on the wrong side of ideology. When we put the first \"Weed\" documentary on television in August 2013, I didn\\'t know if anyone would watch our yearlong investigation. Even worse, I didn\\'t even know if they would care. Is weed legal in your state? Just two years later, in \"Weed 3,\" we are eyewitnesses to a revolution in full swing. You will ride along with us for the dawn of the first federally approved clinical study on the use of marijuana for PTSD. You will meet patients such as Sean Kiernan, an accomplished investment banker, and Amelia Taylor, a stay-at-home mom. They are the remarkable and surprising faces of this revolution -- smart, successful and suffering -- unwilling to accept the fact that commonly prescribed medications often used to treat PTSD can be worse than the underlying disorder itself. Sean Kiernan nearly died, trying to get better. You will see what weed really does to your brain, in crystal clear images. This time around, you will hear from the heads of government agencies earnestly sharing their point of view, both Democratic and Republican senators, and even the President of the United States. This is what a revolution looks like. Your medical marijuana questions answered . When \"Weed 2: Cannabis Madness\" aired in March 2014, Boston researcher Rick Doblin believed the right people were watching. Just four days later, Doblin received a letter in the mail he had been waiting on for seven years that finally provided federal approval for his marijuana study. The federal farm where Doblin would have to obtain his marijuana is on the campus of Ole Miss in Oxford, Mississippi. In anticipation of a scientific revolution, the production of research-grade marijuana there has increased 30-fold in just the past year. Make no mistake, we have plenty of evidence that the approval and support of the federal government can fast track a revolution at a faster pace than we have yet seen. It was the National Institute of Allergy and Infectious Diseases that spearheaded the research into a cure for AIDS, as well as stopping the spread of West Nile Virus. They were also responsible for the awesome task of eradicating polio and smallpox. Other successful federally backed programs include the human genome project, the BRAIN initiative and the Precision Medicine Initiative. There are no shortage of examples where the federal government has been a guardian of our public health needs, and you could argue that medical marijuana would also qualify as a worthwhile investment. 10 diseases where medical marijuana could have impact . There is now promising research into the use of marijuana that could impact tens of thousands of children and adults, including treatment for cancer, epilepsy and Alzheimer\\'s, to name a few. With regard to pain alone, marijuana could greatly reduce the demand for narcotics and simultaneously decrease the number of accidental painkiller overdoses, which are the greatest cause of preventable death in this country. As I sat across from Sens. Kirsten Gillibrand (D-New York) and Cory Booker (D-New Jersey), I knew something extraordinary was happening. They were reciting the story of Charlotte Figi and countless other children. They were quoting back the data we had shared from our earlier investigations. They were extolling the potential virtues of the plant, and all of that was before the interview even started. There was an impatience about them, and they seemed in a hurry to make a large dent in marijuana reform. They want marijuana to be rescheduled. They want it now. They want doctors to be able to prescribe it at VA hospitals all over the country. They want it now. They want research dollars freed up to study the plant. They want it now. They want their fellow lawmakers at the state and national level to acknowledge what most of the world, including the citizens of the United States, have known for a long time: Marijuana is a medicine, that should be studied and treated like any other medicine. And they want all of it now. I spent much of our interview challenging them. I needed to remind them that people, long before me or them, have been trying to do many of these same things for 40 years, and had been rejected every time. I reminded them that politicians have a hard time winning elections on the issue of marijuana but less difficulty losing them. I challenged them every step of the way. \"This time will be different,\" Booker confidently told me as he walked out of the room. Is marijuana as safe as -- or safer than -- alcohol? I know how easy it is do nothing because I did nothing for too long. Take a good look at the data, educate yourself and talk to the patients, who are often out of options and find their hope in the form of a simple plant. Journalists shouldn\\'t take a position. It makes sense. Objectivity is king. But, at some point, open questions do get answered. At some point, contentious issues do get resolved. At some point, common sense prevails. So, here it is: We should legalize medical marijuana. We should do it nationally. And, we should do it now. 9 things to know about legal pot .', 'highlights': 'CNN\\'s Dr. Sanjay Gupta says we should legalize medical marijuana now .\\nHe says he knows how easy it is do nothing \"because I did nothing for too long\"', 'id': '12078b09d95c01cedb06da7fc63faab540432dee'}\n",
      "\n",
      "essg th1: 0.2000, essg th2: 0.4000, essg th3: 0.6000, essg th4: 0.8000, essg autoth: 0.6000 \n",
      "\n",
      "result_base done\n",
      "result_essg1 done\n",
      "result_essg2 done\n",
      "result_essg3 done\n",
      "result_essg4 done\n",
      "result_essg_autoth done\n",
      "data 0,{'mean rouge-2 base': '0.0762', 'mean rouge-2 essg th 0.2': '0.0762', 'mean rouge-2 essg th 0.4': '0.0351', 'mean rouge-2 essg th 0.6': '0.0762', 'mean rouge-2 essg th 0.8': '0.0351', 'mean rouge-2 essg autoth': '0.0762', 'mean time base': '30.2073', 'mean time essg th 0.2': '45.8868', 'mean time essg th 0.4': '15.2664', 'mean time essg th 0.6': '29.1622', 'mean time essg th 0.8': '8.7654', 'mean time essg autoth': '27.9786', 'E2E mean speed up essg th 0.2': '0.6583', 'E2E mean speed up essg th 0.4': '1.9787', 'E2E mean speed up essg th 0.6': '1.0358', 'E2E mean speed up essg th 0.8': '3.4462', 'E2E mean speed up essg autoth': '1.0797', 'mean token time base': '0.0590', 'mean token time essg th 0.2': '0.0896', 'mean token time essg th 0.4': '0.1339', 'mean token time essg th 0.6': '0.0570', 'mean token time essg th 0.8': '0.0769', 'mean token time essg autoth': '0.0546', 'E2E mean token speed up essg th 0.2': '0.6583', 'E2E mean token speed up essg th 0.4': '0.4406', 'E2E mean token speed up essg th 0.6': '1.0358', 'E2E mean token speed up essg th 0.8': '0.7673', 'E2E mean token speed up essg autoth': '1.0797', 'mean matchness essg th 0.2': '0.3464', 'mean matchness essg th 0.4': '0.2017', 'mean matchness essg th 0.6': '0.6242', 'mean matchness essg th 0.8': '0.4667', 'mean matchness essg autoth': '0.6715', 'mean num_drafted_tokens essg th 0.2': '1146.0000', 'mean num_drafted_tokens essg th 0.4': '347.0000', 'mean num_drafted_tokens essg th 0.6': '612.0000', 'mean num_drafted_tokens essg th 0.8': '135.0000', 'mean num_drafted_tokens essg autoth': '557.0000'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "rouge=rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n",
    "main_metrics = {'rouge2_base':[], \n",
    "                'rouge2_essg1':[], 'rouge2_essg2':[], 'rouge2_essg3':[], 'rouge2_essg4':[], \n",
    "                'rouge2_essg_autoth':[],\n",
    "                'time_base':[], \n",
    "                'time_essg1':[], 'time_essg2':[], 'time_essg3':[], 'time_essg4':[], \n",
    "                'time_essg_autoth':[],\n",
    "                'token_time_base':[], \n",
    "                'token_time_essg1':[], 'token_time_essg2':[], 'token_time_essg3':[], 'token_time_essg4':[], \n",
    "                'token_time_essg_autoth':[],\n",
    "                'matchness_essg1':[],'num_drafted_tokens_essg1':[],\n",
    "                'matchness_essg2':[],'num_drafted_tokens_essg2':[],\n",
    "                'matchness_essg3':[],'num_drafted_tokens_essg3':[],\n",
    "                'matchness_essg4':[],'num_drafted_tokens_essg4':[],\n",
    "                'matchness_essg_autoth':[],'num_drafted_tokens_essg_autoth':[]}\n",
    "\n",
    "if True:\n",
    "    for i,x in enumerate(data):\n",
    "        print(x, end='\\n\\n')\n",
    "        input_ids = clip_input(tokenizer, x, task_name, max_new_tokens=512,prompt_shots=prompt_shots)\n",
    "        \n",
    "        if i == 0:\n",
    "            th_stop_draft_essg1 = 0.20\n",
    "            th_stop_draft_essg2 = 0.40\n",
    "            th_stop_draft_essg3 = 0.60\n",
    "            th_stop_draft_essg4 = 0.80\n",
    "            th_stop_draft_essg_autoth  = 0.60\n",
    "        else:\n",
    "            th_stop_draft_essg1 = result_essg1['th_stop_draft']\n",
    "            th_stop_draft_essg2 = result_essg2['th_stop_draft']\n",
    "            th_stop_draft_essg3 = result_essg3['th_stop_draft']\n",
    "            th_stop_draft_essg4 = result_essg4['th_stop_draft']\n",
    "            th_stop_draft_essg_autoth = result_essg_autoth['th_stop_draft']\n",
    "        print('essg th1: {:.4f}, essg th2: {:.4f}, essg th3: {:.4f}, essg th4: {:.4f}, essg autoth: {:.4f} \\n'.format(\n",
    "        th_stop_draft_essg1, th_stop_draft_essg2, th_stop_draft_essg3, th_stop_draft_essg4, th_stop_draft_essg_autoth))\n",
    "        result_base = infer_input_ids(model, tokenizer, input_ids, generate_fn='base',\n",
    "                    max_new_tokens=512, do_sample=False, early_stop=True)\n",
    "        print('result_base done')\n",
    "        result_essg1 = infer_input_ids(model, tokenizer, input_ids, generate_fn='essg', \n",
    "                    max_new_tokens=512, early_stop=True, max_step_draft=12, \n",
    "                    th_stop_draft=th_stop_draft_essg1, auto_th_stop_draft=False,\n",
    "                    do_sample=False, do_sample_draft=False)\n",
    "        print('result_essg1 done')\n",
    "        result_essg2 = infer_input_ids(model, tokenizer, input_ids, generate_fn='essg', \n",
    "                    max_new_tokens=512, early_stop=True, max_step_draft=12, \n",
    "                    th_stop_draft=th_stop_draft_essg2, auto_th_stop_draft=False,\n",
    "                    do_sample=False, do_sample_draft=False)\n",
    "        print('result_essg2 done')\n",
    "        result_essg3 = infer_input_ids(model, tokenizer, input_ids, generate_fn='essg', \n",
    "                    max_new_tokens=512, early_stop=True, max_step_draft=12, \n",
    "                    th_stop_draft=th_stop_draft_essg3,  auto_th_stop_draft=False,\n",
    "                    do_sample=False, do_sample_draft=False)\n",
    "        print('result_essg3 done')\n",
    "        result_essg4 = infer_input_ids(model, tokenizer, input_ids, generate_fn='essg', \n",
    "                    max_new_tokens=512, early_stop=True, max_step_draft=12, \n",
    "                    th_stop_draft=th_stop_draft_essg4,  auto_th_stop_draft=False,\n",
    "                    do_sample=False, do_sample_draft=False)\n",
    "        print('result_essg4 done')\n",
    "        result_essg_autoth = infer_input_ids(model, tokenizer, input_ids, generate_fn='essg', \n",
    "                    max_new_tokens=512, early_stop=True, max_step_draft=12, \n",
    "                    th_stop_draft=th_stop_draft_essg_autoth, auto_th_stop_draft=True, auto_parameters=[1,0.50,0.90,1e-2,0.90],\n",
    "                    do_sample=False, do_sample_draft=False)\n",
    "        print('result_essg_autoth done')\n",
    "\n",
    "        if len(result_base['completion']) < 5 or ('.....' in result_base['completion'][:5]):\n",
    "            print(\"too short, skip\")\n",
    "            continue\n",
    "        \n",
    "        if task_name == 'xsum':\n",
    "            references = x['summary']\n",
    "        elif task_name =='cnndm':\n",
    "            references = x['highlights']\n",
    "            \n",
    "        results = [\n",
    "            ('base', result_base),\n",
    "            ('essg1', result_essg1),\n",
    "            ('essg2', result_essg2),\n",
    "            ('essg3', result_essg3),\n",
    "            ('essg4', result_essg4),\n",
    "            ('essg_autoth', result_essg_autoth)\n",
    "        ]\n",
    "\n",
    "        for key, result in results:\n",
    "            main_metrics['time_' + key].append(result['time'])\n",
    "            main_metrics['token_time_' + key].append(result['time'] / result['generate_ids'].shape[1])\n",
    "            if key != 'base':\n",
    "                main_metrics['matchness_' + key].append(result['matchness'])\n",
    "                main_metrics['num_drafted_tokens_' + key].append(result['num_drafted_tokens'])\n",
    "            clip_pred = result['completion'].find(\"\\nArticle:\")\n",
    "            if clip_pred > 0:\n",
    "                prediction = result['completion'][:clip_pred]\n",
    "            else:\n",
    "                prediction = result['completion']\n",
    "            rouge_score = rouge.score(prediction, references)\n",
    "            main_metrics['rouge2_' + key].append(rouge_score['rouge2'].fmeasure)\n",
    "\n",
    "        metric = {\n",
    "            'mean rouge-2 base':np.mean(main_metrics['rouge2_base']),\n",
    "            f'mean rouge-2 essg th {th_stop_draft_essg1}':np.mean(main_metrics['rouge2_essg1']),\n",
    "            f'mean rouge-2 essg th {th_stop_draft_essg2}':np.mean(main_metrics['rouge2_essg2']),\n",
    "            f'mean rouge-2 essg th {th_stop_draft_essg3}':np.mean(main_metrics['rouge2_essg3']),\n",
    "            f'mean rouge-2 essg th {th_stop_draft_essg4}':np.mean(main_metrics['rouge2_essg4']),\n",
    "            'mean rouge-2 essg autoth':np.mean(main_metrics['rouge2_essg_autoth']),\n",
    "            'mean time base':np.mean(main_metrics['time_base']),\n",
    "            f'mean time essg th {th_stop_draft_essg1}':np.mean(main_metrics['time_essg1']),\n",
    "            f'mean time essg th {th_stop_draft_essg2}':np.mean(main_metrics['time_essg2']),\n",
    "            f'mean time essg th {th_stop_draft_essg3}':np.mean(main_metrics['time_essg3']),\n",
    "            f'mean time essg th {th_stop_draft_essg4}':np.mean(main_metrics['time_essg4']),\n",
    "            'mean time essg autoth':np.mean(main_metrics['time_essg_autoth']),\n",
    "            f'E2E mean speed up essg th {th_stop_draft_essg1}':np.mean(main_metrics['time_base'])/np.mean(main_metrics['time_essg1']),\n",
    "            f'E2E mean speed up essg th {th_stop_draft_essg2}':np.mean(main_metrics['time_base'])/np.mean(main_metrics['time_essg2']),\n",
    "            f'E2E mean speed up essg th {th_stop_draft_essg3}':np.mean(main_metrics['time_base'])/np.mean(main_metrics['time_essg3']),\n",
    "            f'E2E mean speed up essg th {th_stop_draft_essg4}':np.mean(main_metrics['time_base'])/np.mean(main_metrics['time_essg4']),\n",
    "            'E2E mean speed up essg autoth':np.mean(main_metrics['time_base'])/np.mean(main_metrics['time_essg_autoth']),\n",
    "            'mean token time base':np.mean(main_metrics['token_time_base']),\n",
    "            f'mean token time essg th {th_stop_draft_essg1}':np.mean(main_metrics['token_time_essg1']),\n",
    "            f'mean token time essg th {th_stop_draft_essg2}':np.mean(main_metrics['token_time_essg2']),\n",
    "            f'mean token time essg th {th_stop_draft_essg3}':np.mean(main_metrics['token_time_essg3']),\n",
    "            f'mean token time essg th {th_stop_draft_essg4}':np.mean(main_metrics['token_time_essg4']),\n",
    "            'mean token time essg autoth':np.mean(main_metrics['token_time_essg_autoth']),  \n",
    "            f'E2E mean token speed up essg th {th_stop_draft_essg1}':np.mean(main_metrics['token_time_base'])/np.mean(main_metrics['token_time_essg1']),\n",
    "            f'E2E mean token speed up essg th {th_stop_draft_essg2}':np.mean(main_metrics['token_time_base'])/np.mean(main_metrics['token_time_essg2']),\n",
    "            f'E2E mean token speed up essg th {th_stop_draft_essg3}':np.mean(main_metrics['token_time_base'])/np.mean(main_metrics['token_time_essg3']),\n",
    "            f'E2E mean token speed up essg th {th_stop_draft_essg4}':np.mean(main_metrics['token_time_base'])/np.mean(main_metrics['token_time_essg4']),\n",
    "            'E2E mean token speed up essg autoth':np.mean(main_metrics['token_time_base'])/np.mean(main_metrics['token_time_essg_autoth']),          \n",
    "            f'mean matchness essg th {th_stop_draft_essg1}':np.mean(main_metrics['matchness_essg1']),\n",
    "            f'mean matchness essg th {th_stop_draft_essg2}':np.mean(main_metrics['matchness_essg2']),\n",
    "            f'mean matchness essg th {th_stop_draft_essg3}':np.mean(main_metrics['matchness_essg3']),\n",
    "            f'mean matchness essg th {th_stop_draft_essg4}':np.mean(main_metrics['matchness_essg4']),\n",
    "            'mean matchness essg autoth':np.mean(main_metrics['matchness_essg_autoth']),\n",
    "            f'mean num_drafted_tokens essg th {th_stop_draft_essg1}':np.mean(main_metrics['num_drafted_tokens_essg1']),\n",
    "            f'mean num_drafted_tokens essg th {th_stop_draft_essg2}':np.mean(main_metrics['num_drafted_tokens_essg2']),\n",
    "            f'mean num_drafted_tokens essg th {th_stop_draft_essg3}':np.mean(main_metrics['num_drafted_tokens_essg3']),\n",
    "            f'mean num_drafted_tokens essg th {th_stop_draft_essg4}':np.mean(main_metrics['num_drafted_tokens_essg4']),\n",
    "            'mean num_drafted_tokens essg autoth':np.mean(main_metrics['num_drafted_tokens_essg_autoth']),\n",
    "        }\n",
    "        for key, value in metric.items():\n",
    "            if isinstance(value, float):\n",
    "                metric[key] = f\"{value:.4f}\"\n",
    "\n",
    "        # print(f'data {i},{metric}')\n",
    "        print(f'data {i},{metric} \\n')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'E2E mean token speed up essg th 0.2': '0.6583', \n",
    "'E2E mean token speed up essg th 0.4': '0.4406',\n",
    "'E2E mean token speed up essg th 0.6': '1.0358',\n",
    "'E2E mean token speed up essg th 0.8': '0.7673',\n",
    "'E2E mean token speed up essg autoth': '1.0797'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('lg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b2b2094df3d20f295831499431d281eb5aad8ff21e32741728a6f192e048c21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
